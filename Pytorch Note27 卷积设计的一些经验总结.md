# Pytorch Note27 卷积设计的一些经验总结

[toc]

全部笔记的汇总贴：[Pytorch Note 快乐星球](https://blog.csdn.net/weixin_45508265/article/details/117809512)

## 小滤波器的有效性

一般而言，几个小滤波器卷积层的组合比一个大滤波器卷积层要好，比如层层堆叠了3个3x3的卷积层，中间含有非线性激活层，在这种排列下面，第一个卷积层中每个神经元对输人数据的感受野是3x3，第二层卷积层对第一层卷积层的感受野也是3x3，这样对于输人数据的感受野就是5x5，同样，第三层卷积层上对第二层卷积层的感受野是3x3，这样第三层卷积层对于第一层输人数据的感受野就是7x7。

假设这里不使用3个3x3的感受野，直接单独使用一个7x7大小的卷积层,那么所有神经元的感受野也是7x7,但是这样会有一些缺点。多个卷积层首先与非线性激活层交替的结构，比单一卷积层的结构更能提取出深层的特征;其次，假设输人数据体的深度是C,输出体的深度也是C,那么单独的7x7的卷积层会有7x7xCxC=49x$C^2$的参数个数，而使用3个3x3的卷积层的组合,仅仅含有3x(3x3xCxC) = 27x$C^2$的参数。直观来说，选择小滤波器的卷积组合能够对输人数据表达出更有力的特征，同时使用参数也更少。唯一的不足是反向传播更新参数的时候，中间的卷积层可能会占用更多的内存。

## 网络的尺寸

对于卷积神经网络的尺寸设计，没有严格的数学证明，这是根据经验制定出来的规则。
(1)输人层：一般而言,输人层的大小应该能够被2整除很多次，常用的数字包括32，64， 96和224。

(2)卷积层: 卷积层应该尽可能使用小尺寸的滤波器，比如3x3或者5x5，滑动步长取1。还有一点就是需要对输人数据体进行零填充，这样可以有效地保证卷积层不会改变输人数据体的空间尺寸。如果必须要使用更大的滤波器尺寸，比如7x7，通常用在第一个面对原始图像的卷积层上。

(3)池化层: 池化层负责对输人的数据空间维度进行下采样，常用的设置使用2x2的感受野做最大值池化，滑动步长取2。另外一个不常用的设置是使用3x3的感受野步长设置为2。一般而言池化层的感受野大小很少超过3，因为这样会使得池化过程过于激烈，造成信息的丢失，这通常会造成算法的性能变差。

(4)零填充: 零填充的使用可以让卷积层的输入和输出在空间上的维度保持一致，除此之外，如果不使用零填充，那么数据体的尺寸就会略微减少，在不断进行卷积的过程中，图像的边缘信息会过快地损失掉。

